
# **Multi-LLM Question Answering Bot**

A simple project that demonstrates how to build a **question-answering bot** using two different Large Language Models (LLMs): **Groq** and **Gemini**.  
The bot takes a userâ€™s question as input and returns an AI-generated answer.

---

## ğŸš€ **Features**
- Uses **Groq** and **Gemini** models for generating responses.
- Easy to switch between different LLMs.
- Clean Jupyter Notebook implementations (`main_groq.ipynb` and `main_gemini.ipynb`).

---

## ğŸ“‚ **Project Structure**

â”œâ”€â”€ main_gemini.ipynb # Notebook using Gemini API

â”œâ”€â”€ main_groq.ipynb # Notebook using Groq API

â”œâ”€â”€ .gitignore # Hides .env and other sensitive files

â””â”€â”€ README.md # Project documentation


---

## âš™ï¸ **Setup**
1. **Clone the repository**
   ```bash
   git clone https://github.com/MuhammadHamza123c/langchain-qa-bot.git
   cd langchain-qa-bot


## **Create a .env file and add your API keys**:

GROQ_API_KEY=your_groq_api_key_here

GEMINI_API_KEY=your_gemini_api_key_here


## **Open a notebook in Jupyter or Google Colab**:

main_gemini.ipynb

main_groq.ipynb

 Run the cells and start asking questions!


## ğŸ“š **Tech Stack**

Python

Jupyter Notebook

Groq API

Gemini API

Lang Chain

## ğŸ¤ **Contributing**

Pull requests are welcome! For major changes, please open an issue first to discuss what you would like to change.
